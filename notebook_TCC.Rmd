---
title: "Time Series Notebook"
output:
  html_document:
    df_print: paged
---


### **Pacotes utilizados**

```{r}
library(astsa) # para analisar séries temporais
library(tsibble)  # para trabalhar com séries temporais
library(tidyverse) ### para manipulação e tratamento dos dados
library(forecast)
library(zoo)
library(readxl)
library(ggplot2)
library(ggfortify)
library(tidyverse)
library(zoo)
library(magrittr)
library(GGally)
library(tsibble) # para trabalhar com séries temporais
library(corrplot)
library(gridExtra)
```


#### **Tratamento da base**

Primeiro carregamos a base de dados, iniciamos nossa análise com 19 variáveis e 2613 observações.

```{r}
MMM_data <- read_excel("MMM_data_excel.xlsx", 
                                 col_types = c("text", "date", "numeric", 
                                                    "numeric", "numeric", "numeric", 
                                                    "numeric", "numeric", "numeric", 
                                                    "numeric", "numeric", "numeric", 
                                                    "numeric", "numeric", "numeric", 
                                                    "numeric", "numeric", "numeric","numeric"))

head(MMM_data)
dim(MMM_data)
str(MMM_data)

```


### **ANÁLISE EXPLORATÓRIA**

```{r}

options (scipen = 999)
summary(MMM_data)

```


```{r}

MMM_nonnumeric <- MMM_data[,-c(1,2)] ### apenas valores númericos
tb <- MMM_nonnumeric %>% 
  gather(key = "variable", value = "value", -DEMAND)

ggplot(tb,
       mapping = aes( x= value, y = DEMAND)) +
  facet_wrap(facets = ~variable, scale = "free_x") +
  scale_y_sqrt()+
  geom_point() 

```


```{r}

MMM_cost <- MMM_data[, -c(1,4,5,6,15,16,17,18,19)] # sem os dados de GRP
ggpairs(MMM_cost)

```



```{r}
## RESPOSTA ------------------------------------------

Sales <- ggplot(MMM_data, aes(x = DATE, y = SALES)) +
  geom_line()
supply <- ggplot(MMM_data, aes(x = DATE, y = Supply_Data)) +
  geom_line()
unit <- ggplot(MMM_data, aes(x = DATE, y = Unit_Price)) +
  geom_line()
demand <- ggplot(MMM_data, aes(x = DATE, y = DEMAND)) +
  geom_line()

grid.arrange(Sales, supply, unit, demand,  nrow = 4)

```

Escolhemos demanda como nossa variável resposta


```{r}

## MACROECONOMICA -----------------------------------

PPI <-ggplot(MMM_data, aes(x = DATE, y = PPI)) +
  geom_line()

CCI <- ggplot(MMM_data, aes(x = DATE, y = CCI)) +
  geom_line()

CPI <- ggplot(MMM_data, aes(x = DATE, y = CPI)) +
  geom_line()

grid.arrange(PPI, CCI, CPI,  nrow = 3)


```

Como é possível observar as varipaveis estão com agregações diferentes, as variáveis macroeconomicas estão no formato mês e as demais estão diárias.

Optamos em transformar a base para o formato **mês** devido ao comportamente mensal das variaveis macroeconomicas observadas,combinado a ideia de que a série traz muitos ruídos em suas variaveis, talvez a agregação pudesse ajudar a suavizar o comportamento das outras variáveis e reduzir o ruído.

```{r}
only_data2<-data_cyn2[,c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,20)]

teste<-only_data %>%
  group_by(indice_semana) %>%
  summarise(weekly_demand = sum(DEMAND),
            weekly_mean_unit_price=mean(Unit_Price),
            weekly_supply_data=sum(Supply_Data),
            weekly_sales=sum(SALES),
            weekly_cost_sms=sum(Cost_SMS),
            weekly_cost_newspapers=sum(Cost_Newspaper),
            weekly_cost_radio=sum(Cost_Radio),
            weekly_cost_tv=sum(Cost_TV))


teste2<-only_data2 %>%
  group_by(anomes) %>%
  summarise(m_demand = sum(DEMAND),
            m_mean_unit_price=mean(Unit_Price),
            m_supply_data=sum(Supply_Data),
            m_sales=sum(SALES),
            m_cost_sms=sum(Cost_SMS),
            m_cost_newspapers=sum(Cost_Newspaper),
            m_cost_radio=sum(Cost_Radio),
            m_cost_tv=sum(Cost_TV),
            m_cost_internet = sum(Cost_Internet),
            m_CPI=mean(CPI),
            m_CCI=mean(CCI),
            m_PPI=mean(PPI))



dia <- ggplot(MMM_data, aes(x = DATE, y = DEMAND)) +
  geom_line()
semana <- ggplot(teste, aes(x = indice_semana, y = weekly_demand)) +
  geom_line()
mes <- ggplot(teste2, aes(x = ind_mes, y = m_demand)) +
  geom_line()
grid.arrange(dia, semana, mes,  nrow = 3)
```


```{r}

str(MMM_data)
data_cyn<-MMM_data
head(data_cyn)
str(data_cyn)
data_cyn2<-MMM_data


data_cyn2<-MMM_data

data_cyn2$DATE <- as.Date(data_cyn2$DATE)
data_cyn2$anomes<-as.yearmon(data_cyn2$DATE, "%b-%y") %>%
    format(., "%Y-%m")


#desconsiderando apenas os dados de GRP numa nova tabela e agregando por mes
only_data2<-data_cyn2[,c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,20)]
teste2<-only_data2 %>%
  group_by(anomes) %>%
  summarise(m_demand = sum(DEMAND),
            m_mean_unit_price=mean(Unit_Price),
            m_supply_data=sum(Supply_Data),
            m_sales=sum(SALES),
            m_cost_sms=sum(Cost_SMS),
            m_cost_newspapers=sum(Cost_Newspaper),
            m_cost_radio=sum(Cost_Radio),
            m_cost_tv=sum(Cost_TV),
            m_cost_internet = sum(Cost_Internet),
            m_CPI=mean(CPI),
            m_CCI=mean(CCI),
            m_PPI=mean(PPI))

library(lubridate) #inserindo indice para observações do mês
teste2$ind_mes<-seq.int(nrow(teste2))
str(teste2)
head(teste2)

#transformando anomes em data
teste2$data<-as.Date(teste2$anomes, format = "%m/%Y")
str(teste2)

teste2$data<-ym(teste2$anomes)
str(teste2)

teste2$somes<-format(teste2$data,"%m")

teste2$soano<-format(teste2$data,"%Y")
str(teste2)
base_de_dados<-teste2

```


```{r}

### MACRO ECONOMICOS
ggplot(teste2, aes(x =ind_mes, y = m_PPI)) + geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_CCI)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_PPI)) +
  geom_line()

## VENDAS
ggplot(teste2, aes(x = ind_mes, y = m_demand)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_mean_unit_price)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_supply_data)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_sales)) +
  geom_line()
```
Aqui é visivel como a agregação nos dados reduziu o ruído nos graficos.



```{r}

##Investimento em canais
ggplot(teste2, aes(x = ind_mes, y = m_cost_sms)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_cost_tv)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_cost_newspapers)) +
  geom_line()

ggplot(teste2, aes(x = ind_mes, y = m_cost_radio)) +
  geom_line()
```


### **ANALISE DE AUTOCORRELAÇÃO CRUZADA**

```{r}

acf2(teste2$m_cost_sms)## 
acf2(teste2$m_cost_tv) 
acf2(teste2$m_cost_newspapers)
acf2(teste2$m_cost_radio)
acf2(teste2$m_cost_internet)
acf2(teste2$m_demand)
acf2(teste2$m_sales)
acf2(teste2$m_supply_data)
acf2(teste2$m_PPI)
acf2(teste2$m_CCI)
acf2(teste2$m_CPI)



```
Olhando para o ACF de demanda podemos ver que talvez seja necessário trabalhar com diferença para tornar os dados estacionários.

### **TRANSFORMAND DADOS EM SERIES TEMPORAIS**

```{r}

dados_mes <- read_excel("dados_mensais.xlsx")
# dados em formato de séries temporais
str(dados_mes)
dados_mes_ts<-ts(dados_mes, frequency=12, start=c(2010,1))
str(dados_mes_ts)
head(dados_mes_ts)
str(dados_mes_ts)

```

### **DECOMPOSIÇÃO**

```{r}

########### PARA VARIAVEL RESPOSTA ###################

ts_demanda<-ts(dados_mes$m_demand, frequency=12, start=c(2010,1))
str(ts_demanda)
head(ts_demanda)

dadossazonais<- decompose(ts_demanda)
plot(dadossazonais)



##### VERIFICAR PARA OUTRAS VARIÁVEIS ################################


#####   trocar variavel para verificar decomposição
dados_mes_ts<-ts(dados_mes$m_cost_internet, frequency=12, start=c(2010,1))
str(dados_mes_ts)
head(dados_mes_ts)

sazidata<- decompose(dados_mes_ts)
plot(sazidata)

```





## **TSLM**

##### ANÁLISE DE REGRESSÃO MULTIPLA

```{r}


rm1 <- lm(m_demand ~ m_PPI + m_CCI + m_CPI + m_sales + m_supply_data + m_mean_unit_price + 
            m_cost_sms +  m_cost_newspapers + m_cost_radio + m_cost_tv + m_cost_internet,
            data = dados_mes)

summary(rm1)

par(mfrow = c(2,2))
plot(rm1, which = c(1:4), pch = 20)

rm2 <- lm(m_demand ~ m_CCI + m_CPI + m_sales + m_supply_data + m_mean_unit_price + 
            m_cost_sms +  m_cost_newspapers + m_cost_radio + m_cost_tv + m_cost_internet,
          data = dados_mes)

summary(rm2)

par(mfrow = c(2,2))
plot(rm2, which = c(1:4), pch = 20)


rm3 <- lm(m_demand ~ m_CCI + m_CPI + m_sales + m_supply_data + m_mean_unit_price + 
            m_cost_sms +  m_cost_newspapers + m_cost_tv + m_cost_internet,
          data = dados_mes)

summary(rm3)

par(mfrow = c(2,2))
plot(rm3, which = c(1:4), pch = 20)

rm4 <- lm(m_demand ~ m_CCI + m_CPI + m_sales + m_supply_data + m_mean_unit_price + 
            m_cost_sms +  m_cost_newspapers + m_cost_tv,
          data = dados_mes)

summary(rm4)

par(mfrow = c(2,2))
plot(rm4, which = c(1:4), pch = 20)

rm5 <- lm(m_demand ~ m_CCI + m_CPI + m_sales + m_supply_data + 
            m_cost_sms +  m_cost_newspapers + m_cost_tv,
          data = dados_mes)

summary(rm5)

par(mfrow = c(2,2))
plot(rm5, which = c(1:4), pch = 20)

rm6 <- lm(m_demand ~ m_CPI +m_supply_data + 
            m_cost_sms +  m_cost_newspapers + m_cost_tv,
          data = dados_mes)

summary(rm6)

par(mfrow = c(2,2))
plot(rm5, which = c(1:4), pch = 20)

#### Ultimo modelo contem 5 variaveis mais o intercepto que explicam a demanda (variável resposta)

#### Vale comentar que esse não tem as melhores medidas de seleção do modelo,
#### o erro padrão residual aumenta e o R- quadrado dminui nessa análise


library(mctest)
library(lmtest)


imcdiag(rm6, "VIF")

# modelo apresenta multicolinearidade


```

Possui problemas de multicolinearidade.

Fico meio em duvida sobre a qualidade dos dados selecionados para a análise.





```{r}


data_new_escala <-
  dados_mes %>% 
  transform(m_demand = m_demand/1000,
            m_supply_data  = m_supply_data/1000,
            m_mean_unit_price = m_mean_unit_price/1000,
            m_sales = m_sales/1000,
            m_cost_sms = m_cost_sms/1000,
            m_cost_newspapers = m_cost_newspapers/1000,
            m_cost_radio = m_cost_radio/1000,
            m_cost_tv  = m_cost_tv/1000,
            m_cost_internet  = m_cost_internet/1000,
            m_CPI = m_CPI/1000,
            m_CCI  = m_CCI/1000,
            m_PPI  = m_PPI/1000)


str(data_new_escala)


summary(data_new_escala)


str(data_new_escala)
summary(data_new_escala)


data_ts_scale<-ts(data_new_escala, frequency=12, start=c(2010,1))
str(data_ts_scale)
head(data_ts_scale)
str(data_ts_scale)

############################## ARIMA PARA DEMANDA ####################################################


```







##### COM TSLM

```{r}


ts1 <- tslm(m_demand ~ season + trend + m_PPI + m_CCI + m_CPI + m_sales + m_supply_data
            + m_mean_unit_price +m_cost_sms + m_cost_newspapers + m_cost_radio 
            + m_cost_tv + m_cost_internet, 
            data = data_ts_scale)

summary(ts1)
anova(ts1)
checkresiduals(ts1)

ts2 <- tslm(m_demand ~ season + trend + m_CCI + m_CPI + m_sales + m_supply_data
            + m_mean_unit_price +m_cost_sms + m_cost_newspapers + m_cost_radio 
            + m_cost_tv + m_cost_internet, 
            data = data_ts_scale)

summary(ts2)
anova(ts2)
checkresiduals(ts2)

ts3 <- tslm(m_demand ~ season + m_CCI + m_CPI + m_sales + m_supply_data
            + m_mean_unit_price +m_cost_sms + m_cost_newspapers + m_cost_radio 
            + m_cost_tv + m_cost_internet, 
            data = data_ts_scale)

summary(ts3)
anova(ts3)
checkresiduals(ts3)

ts4 <- tslm(m_demand ~ season + m_CCI + m_CPI + m_sales + m_supply_data
            + m_mean_unit_price +m_cost_sms + m_cost_newspapers 
            + m_cost_tv + m_cost_internet, 
            data = data_ts_scale)

summary(ts4)
anova(ts4)
checkresiduals(ts4)

ts5 <- tslm(m_demand ~ season + m_CCI + m_CPI + m_sales + m_supply_data
            + m_mean_unit_price +m_cost_sms + m_cost_newspapers 
            + m_cost_tv, 
            data = data_ts_scale)

summary(ts5)
anova(ts5)
checkresiduals(ts5)

ts6 <- tslm(m_demand ~ season + m_CPI + m_sales + m_supply_data
            + m_mean_unit_price +m_cost_sms + m_cost_newspapers 
            + m_cost_tv, 
            data = data_ts_scale)

summary(ts6)
anova(ts6)
checkresiduals(ts6)



ts7 <- tslm(m_demand ~ season + m_CPI + m_sales + m_supply_data
           +m_cost_sms + m_cost_newspapers 
            + m_cost_tv, 
            data = data_ts_scale)

summary(ts7)
anova(ts7)
checkresiduals(ts7)

ts8 <- tslm(m_demand ~ season + m_CPI + m_supply_data
            +m_cost_sms + m_cost_newspapers 
            + m_cost_tv, 
            data = data_ts_scale)

summary(ts8)
anova(ts8)
checkresiduals(ts8)

```




### **ANALISE DE SERIES TEMPORAIS PARA DEMANDA**






```{r}

##### ANALISE DE TENDENCIA

ts_demanda<-ts(data_new_escala$m_demand, frequency=12, start=c(2010,1))
str(ts_demanda)
head(ts_demanda)

dadossazonais<- decompose(ts_demanda)
plot(dadossazonais)


```


```{r}

############## MÉDIAS MÓVEIS #########################################

autoplot(ts(data_new_escala$m_demand)) +
  autolayer(ma(data_new_escala$m_demand,7), series="5-MA") +
  xlab("Year") + ylab("Demand") +
  scale_colour_manual(values=c("Data"="grey50","5-MA"="red"),
                      breaks=c("Data","5-MA"))

########### AUTOCORRELAÇÃO #########################

acf(data_new_escala$m_demand)
acf2(data_new_escala$m_demand)

#################### plotando ajuste do modelo ############################

lag1.plot(data_new_escala$m_demand,5)
fit<- lm(data_new_escala$m_demand ~ data_new_escala$data, na.action = NULL)
summary(fit)

###lag 1 para autoregressão

#################
```
Problema com a diferença, transformar os dados diff() para os dados ficarem estacionários


```{r}

## retifica??o e diferen?a
par(mfrow=c(2,1), mar=c(3,3,1,1), mgp=c(1.6,.6,0))
plot(data_new_escala$m_demand-fitted(fit),x= data_new_escala$data, xlab="Tempo", ylab="Série do resto", pch=19, col="skyblue3", type = "l")
grid()
plot(diff(data_new_escala$m_demand,1), xlab="Tempo", ylab="Série diferenciada", pch=19, col="skyblue3", type = "l")
grid()

### AQUI PODEMOS VER QUE COM A DIFERENÇA A SERIE PASSA A SER ESTACIONÁRIA
### TALVEZ SEJA UMA DAS ABORDAGENS UTILIZADAS NA NOSSA ANÁLISE

########## correlação cruzada para a diferença

acf2(data_new_escala$m_demand-fitted(fit))


acf2(diff(data_new_escala$m_demand))

#########

sarima(data_new_escala$m_demand,0,1,0)
sarima(data_new_escala$m_demand,0,1,1) #### melhor modelo
sarima(data_new_escala$m_demand,1,1,0)

auto.arima(data_new_escala$m_demand)


```



"Como você sabe, o ACF está relacionado à parte MA e o PACF à parte AR, portanto, como no pacf temos uma barra que excede muito o intervalo de confiança, estamos confiantes de que nossos dados têm raiz unitária e podemos nos livrar dela diferenciando os dados por um. Em termos ARIMA, os dados devem ser integrados por 1 (d=1), e esta é a parte I de arima. Além disso, como não temos decaimento de barras no PACF, o modelo não teria nenhum lag incluído na parte AR. Considerando que, no gráfico ACF, todas as barras estão muito longe do intervalo de confiança, o modelo teria muitos atrasos da parte MA."





#### **MODELO COM AS COVARIAVEIS**


```{r}


dim(data_new_escala)
str(data_new_escala)
num_data <- data_new_escala[,c(-1,-16,-17)]
str(num_data)


train <-  num_data[1:78, ]
test <- num_data[-c(1:78), ]




dim(train)
dim(test)


str(train)
# head(midiacov)
head(train)



head(test)
# par(mfrow = c(3,1))
# plot(y=macrocov$m_CPI, x=data_new_escala$data, type = "l")
# plot(y=macrocov$m_PPI, x=data_new_escala$data, type = "l")
# plot(y=macrocov$m_CCI, x=data_new_escala$data, type = "l")
# dev.off()


macrocov <- train[, c(10:12)]
vendacov <- train[, c(2:4)]
midiacov <- train[, c(5:9)]

autoplot(ts(midiacov))
autoplot(ts(vendacov))
autoplot(ts(macrocov))
plot.ts(midiacov)

###### Aqui podemos ver que as varivaeis de custo são estacionárias e apresentam
##### comportamento ciclico, quanto as macroeconomicas e de vendas possue
##### tendencia e sazonalidade, logo são não estacionárias


cov <- train[,c(2:12)]
str(cov)
cov<-as.matrix(cov) ### precisa transformar em matriz antes de colocar no modelo


######## DECOMPOSIÇÃO DAS VARIAVEIS DE MIDIA ########################
ts_cost<-ts(train$m_cost_tv, frequency=12, start=c(2010,1))
str(ts_cost)
head(ts_cost)

dsazonais<- decompose(ts_cost)
plot(dsazonais)

######################################################################

arima(train$m_demand, xreg = cov, order = c(0,1,1))
sarima(train$m_demand, xreg = cov, 0,1,1)

#### fazemos a verificação com os argumentos do modelo apenas para demanda
#### Apesar de ter funcionado para a demanda não é um bom modelo para as
#### covariaveis, pois apresenta um valor abaixo do p-valor 




##### ANALISANDO MÉDIA MÓVEL ###########

autoplot(ts(data_new_escala$m_cost_radio)) +
  autolayer(ma(data_new_escala$m_cost_radio,2), series="5-MA") +
  xlab("Year") + ylab("Demand") +
  scale_colour_manual(values=c("Data"="grey50","5-MA"="red"),
                      breaks=c("Data","5-MA"))



#### A estacionaridade tem que ficar na linha do zero, com o acrescimo da média
#### móvel em midia, podemos suavizar a linha e aproximar de zero
#########################################################



fit1<- arima(train$m_demand, xreg = cov, order = c(1,0,1))

checkresiduals(fit1)

sarima(train$m_demand, xreg = cov, 1,0,1)

fit2 <- arima(train$m_demand, xreg = cov, order = c(2,0,2))

checkresiduals(fit2)

sarima(train$m_demand, xreg = cov, 2,0,2)


fit3 <- arima(train$m_demand, xreg = cov, order = c(3,0,2))

checkresiduals(fit3)

sarima(train$m_demand, xreg = cov, 3,0,2)

fit4 <- arima(train$m_demand, xreg = cov, order = c(4,0,2))

checkresiduals(fit4)
#### entender a saída
sarima(train$m_demand, xreg = cov, 4,0,2)
#### ENTENDER A SAÍDA DO SARIMA


AIC(fit3)  #### melhor modelo ajustado
AIC(fit4)


sarima(train$m_demand, xreg = cov, 3,0,2)  ####  


##### PREDIÇÃO

cov_test <- test[,c(2:12)]
str(cov_test)
cov_test<-as.matrix(cov_test)


dev.off()
sarima.for(train$m_demand,
           xreg = cov, 
           newxreg = cov_test[c(1:8),], 8,
           3,0,2)


ggplot(test, aes(x = data , y = m_demand)) +
  geom_line()

```



Como o valor p é muito maior que o nível de significância de 5%, não rejeitamos a hipótese nula de que os erros não são autocorrelacionados. No entanto, observando o gráfico ACF, temos algumas barras que saem do intervalo de confiança, mas isso pode ser esperado pelo nível de significância de 5% (como falso positivo). Assim podemos confirmar a não correlação com 95% de confiança.



 
 
#### RNN

```{r}
library(neuralnet)
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret)
library(readxl)
```

